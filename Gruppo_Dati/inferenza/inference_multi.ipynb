{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if inference_results directory does not exist, create it\n",
    "if not os.path.exists(\"inference_results\"):\n",
    "    os.makedirs(\"inference_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# LOAD MODELS AND ENCODERS\n",
    "# ============================================================================\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"model_categoria.pkl\"), \"rb\") as f:\n",
    "    model_categoria = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"model_classe.pkl\"), \"rb\") as f:\n",
    "    model_classe = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"label_encoders_final.pkl\"), \"rb\") as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "le_categoria = label_encoders[\"CATEGORIA\"]\n",
    "le_classe = label_encoders[\"CLASSE\"]\n",
    "\n",
    "df_model_reference = pd.read_csv(os.path.join(DATA_DIR, \"df_model.csv\"), low_memory=False)\n",
    "\n",
    "print(\"Models and encoders loaded successfully\")\n",
    "\n",
    "# Get expected features\n",
    "expected_features_cat = model_categoria.feature_names_in_\n",
    "expected_features_classe = model_classe.feature_names_in_\n",
    "\n",
    "print(f\"CATEGORIA model features: {len(expected_features_cat)}\")\n",
    "print(f\"CLASSE model features: {len(expected_features_classe)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# LOAD INPUT\n",
    "# ============================================================================\n",
    "df_input = pd.read_csv(\"sample_input.csv\")\n",
    "print(f\"Input data loaded: {df_input.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PREPROCESSING\n",
    "# ============================================================================\n",
    "df_processed = df_input.copy()\n",
    "\n",
    "# Add missing columns for CATEGORIA\n",
    "for col in expected_features_cat:\n",
    "    if col not in df_processed.columns:\n",
    "        if col in df_model_reference.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df_model_reference[col]):\n",
    "                df_processed[col] = df_model_reference[col].median()\n",
    "            else:\n",
    "                df_processed[col] = df_model_reference[col].mode()[0] if len(df_model_reference[col].mode()) > 0 else 0\n",
    "        else:\n",
    "            df_processed[col] = 0\n",
    "\n",
    "# Process numeric columns\n",
    "for col in expected_features_cat:\n",
    "    if col in df_model_reference.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_model_reference[col]):\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "            df_processed[col] = df_processed[col].fillna(df_model_reference[col].median())\n",
    "\n",
    "# Process categorical columns\n",
    "for col, le in label_encoders.items():\n",
    "    if col in expected_features_cat and col != 'CATEGORIA' and col != 'CLASSE':\n",
    "        most_frequent = le.classes_[0]\n",
    "        df_processed[col] = df_processed[col].fillna(most_frequent).astype(str)\n",
    "        df_processed[col] = df_processed[col].apply(lambda x: x if x in le.classes_ else most_frequent)\n",
    "        df_processed[col] = le.transform(df_processed[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 1: PREDICT CATEGORIA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: CATEGORIA PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_cat = df_processed[expected_features_cat]\n",
    "pred_cat_encoded = model_categoria.predict(X_cat)\n",
    "pred_cat = le_categoria.inverse_transform(pred_cat_encoded)\n",
    "proba_cat = model_categoria.predict_proba(X_cat)\n",
    "\n",
    "print(f\"\\nTop 3 CATEGORIA predictions:\")\n",
    "top3_cat_indices = np.argsort(proba_cat[0])[-3:][::-1]\n",
    "for i, idx in enumerate(top3_cat_indices, 1):\n",
    "    cat_name = le_categoria.classes_[idx]\n",
    "    confidence = proba_cat[0][idx]\n",
    "    print(f\"  {i}. {cat_name}: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SHAP EXPLAINABILITY - CATEGORIA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SHAP ANALYSIS - CATEGORIA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Computing SHAP values...\")\n",
    "explainer_cat = shap.TreeExplainer(model_categoria)\n",
    "shap_values_cat = explainer_cat.shap_values(X_cat)\n",
    "\n",
    "# Extract values for predicted class\n",
    "if isinstance(shap_values_cat, np.ndarray) and shap_values_cat.ndim == 3:\n",
    "    shap_values_cat_pred = shap_values_cat[0, :, pred_cat_encoded[0]]\n",
    "    base_value = explainer_cat.expected_value[pred_cat_encoded[0]]\n",
    "elif isinstance(shap_values_cat, list):\n",
    "    shap_values_cat_pred = shap_values_cat[pred_cat_encoded[0]][0]\n",
    "    base_value = explainer_cat.expected_value[pred_cat_encoded[0]]\n",
    "else:\n",
    "    shap_values_cat_pred = shap_values_cat[0]\n",
    "    base_value = explainer_cat.expected_value\n",
    "\n",
    "# Top 30 most influential features\n",
    "shap_importance_cat = pd.DataFrame({\n",
    "    'feature': expected_features_cat,\n",
    "    'shap_value': shap_values_cat_pred,\n",
    "    'feature_value': X_cat.iloc[0].values\n",
    "})\n",
    "shap_importance_cat['abs_shap'] = shap_importance_cat['shap_value'].abs()\n",
    "shap_top30 = shap_importance_cat.sort_values('abs_shap', ascending=False).head(30)\n",
    "\n",
    "# Top 10 features that increased probability (positive SHAP)\n",
    "shap_positive = shap_importance_cat[shap_importance_cat['shap_value'] > 0].sort_values('shap_value', ascending=False).head(10)\n",
    "\n",
    "# Top 10 features that decreased probability (negative SHAP)\n",
    "shap_negative = shap_importance_cat[shap_importance_cat['shap_value'] < 0].sort_values('shap_value', ascending=True).head(10)\n",
    "\n",
    "print(f\"\\nTop 30 most influential features for CATEGORIA={pred_cat[0]}:\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in shap_top30.iterrows():\n",
    "    direction = \"positive\" if row['shap_value'] > 0 else \"negative\"\n",
    "    print(f\"  {row['feature']}: {row['feature_value']:.2f} | SHAP: {row['shap_value']:+.4f} ({direction})\")\n",
    "\n",
    "print(f\"\\nTop 10 features that INCREASED probability:\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in shap_positive.iterrows():\n",
    "    print(f\"  {row['feature']}: {row['feature_value']:.2f} | SHAP: {row['shap_value']:+.4f}\")\n",
    "\n",
    "print(f\"\\nTop 10 features that DECREASED probability:\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in shap_negative.iterrows():\n",
    "    print(f\"  {row['feature']}: {row['feature_value']:.2f} | SHAP: {row['shap_value']:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE COMPREHENSIVE VISUALIZATION REPORT\n",
    "# ============================================================================\n",
    "\n",
    "fig = plt.figure(figsize=(20 , 12))\n",
    "gs = fig.add_gridspec(3, , hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Top predictions and confidences (top left)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.axis('off')\n",
    "\n",
    "# CATEGORIA predictions\n",
    "cat_text = \"CATEGORIA PREDICTIONS\\n\" + \"\\n\"\n",
    "for i, idx in enumerate(top3_cat_indices, 1):\n",
    "    cat_name = le_categoria.classes_[idx]\n",
    "    confidence = proba_cat[0][idx]\n",
    "    marker = \"→\" if i == 1 else \" \"\n",
    "    cat_text += f\"{marker} {i}. {cat_name}: {confidence:.4f} -\"\n",
    "\n",
    "# CLASSE predictions\n",
    "cat_text += \"\\n\\nCLASSE PREDICTIONS\\n\" + \"\\n\"\n",
    "for i, idx in enumerate(top3_classe_indices, 1):\n",
    "    classe_name = le_classe.classes_[idx]\n",
    "    confidence = proba_classe[0][idx]\n",
    "    marker = \"→\" if i == 1 else \" \"\n",
    "    cat_text += f\"{marker} {i}. {classe_name}: {confidence:.4f} -\"\n",
    "\n",
    "cat_text += \"\\n\\nFINAL PREDICTION\\n\" + \"\\n\"\n",
    "cat_text += f\"{pred_cat[0]}/{pred_classe[0]}\\n\"\n",
    "cat_text += f\"CATEGORIA conf: {proba_cat[0][pred_cat_encoded[0]]:.4f}\\n\"\n",
    "cat_text += f\"CLASSE conf: {proba_classe[0][pred_classe_encoded[0]]:.4f}\"\n",
    "\n",
    "ax1.text(0.1, 0.5, cat_text, fontsize=7, family='monospace', verticalalignment='center')\n",
    "ax1.set_title('Predictions Summary', fontsize=6, fontweight='bold', pad=20)\n",
    "\n",
    "# 2. SHAP Waterfall (top right - spans 2 rows)\n",
    "ax2 = fig.add_subplot(gs[0:2, 1])\n",
    "plt.sca(ax2)\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values_cat_pred,\n",
    "        base_values=base_value,\n",
    "        data=X_cat.iloc[0].values,\n",
    "        feature_names=expected_features_cat\n",
    "    ),\n",
    "    show=False,\n",
    "    max_display=5\n",
    ")\n",
    "ax2.set_title(f'SHAP Waterfall - CATEGORIA: {pred_cat[0]}', fontsize=6, fontweight='bold', pad=10)\n",
    "\n",
    "# 3. Top 10 Positive SHAP (bottom left)\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "if len(shap_positive) > 0:\n",
    "    features_pos = shap_positive['feature'].head(10).tolist()\n",
    "    values_pos = shap_positive['shap_value'].head(10).tolist()\n",
    "    y_pos = np.arange(len(features_pos))\n",
    "    \n",
    "    ax3.barh(y_pos, values_pos, color='green', alpha=0.7)\n",
    "    ax3.set_yticks(y_pos)\n",
    "    ax3.set_yticklabels(features_pos, fontsize=5)\n",
    "    ax3.set_xlabel('SHAP Value', fontsize=5)\n",
    "    ax3.set_title('Top 10 Features (Increased Probability)', fontsize=6, fontweight='bold')\n",
    "    ax3.invert_yaxis()\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Top 10 Negative SHAP (bottom right)\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "if len(shap_negative) > 0:\n",
    "    features_neg = shap_negative['feature'].head(10).tolist()\n",
    "    values_neg = shap_negative['shap_value'].head(10).tolist()\n",
    "    y_neg = np.arange(len(features_neg))\n",
    "    \n",
    "    ax4.barh(y_neg, values_neg, color='red', alpha=0.7)\n",
    "    ax4.set_yticks(y_neg)\n",
    "    ax4.set_yticklabels(features_neg, fontsize=5)\n",
    "    ax4.set_xlabel('SHAP Value', fontsize=5)\n",
    "    ax4.set_title('Top 10 Features (Decreased Probability)', fontsize=6, fontweight='bold')\n",
    "    ax4.invert_yaxis()\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 5. Top 30 Summary table (bottom right)\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "ax5.axis('off') \n",
    "\n",
    "top10_summary = shap_top30.head(10)\n",
    "table_data = []\n",
    "for idx, row in top10_summary.iterrows():\n",
    "    table_data.append([\n",
    "        row['feature'][:20],  # Truncate long names\n",
    "        f\"{row['feature_value']:.1f}\",\n",
    "        f\"{row['shap_value']:+.3f}\"\n",
    "    ])\n",
    "\n",
    "table = ax5.table(cellText=table_data, \n",
    "                  colLabels=['Feature', 'Value', 'SHAP'],\n",
    "                  cellLoc='left',\n",
    "                  loc='center',\n",
    "                  colWidths=[0.5, 0.15, 0.2])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style header\n",
    "for i in range(3):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "ax5.set_title('Top 10 Most Influential Features', fontsize=6, fontweight='bold', pad=20)\n",
    "\n",
    "plt.suptitle('Model Prediction Report with SHAP Analysis', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.savefig('inference_results/prediction_report.pdf', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nComprehensive report saved: prediction_report.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PREDICT CLASSE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: CLASSE PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add predicted CATEGORIA\n",
    "df_processed['CATEGORIA_encoded'] = pred_cat_encoded\n",
    "\n",
    "# Add missing columns for CLASSE\n",
    "for col in expected_features_classe:\n",
    "    if col not in df_processed.columns:\n",
    "        if col in df_model_reference.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df_model_reference[col]):\n",
    "                df_processed[col] = df_model_reference[col].median()\n",
    "            else:\n",
    "                df_processed[col] = df_model_reference[col].mode()[0] if len(df_model_reference[col].mode()) > 0 else 0\n",
    "        else:\n",
    "            df_processed[col] = 0\n",
    "\n",
    "# Process categorical columns for CLASSE\n",
    "for col, le in label_encoders.items():\n",
    "    if col in expected_features_classe and col != 'CLASSE':\n",
    "        if col not in ['CATEGORIA_encoded']:\n",
    "            if col in df_processed.columns:\n",
    "                most_frequent = le.classes_[0]\n",
    "                df_processed[col] = df_processed[col].fillna(most_frequent).astype(str)\n",
    "                df_processed[col] = df_processed[col].apply(lambda x: x if x in le.classes_ else most_frequent)\n",
    "                df_processed[col] = le.transform(df_processed[col])\n",
    "\n",
    "X_classe = df_processed[expected_features_classe]\n",
    "\n",
    "pred_classe_encoded = model_classe.predict(X_classe)\n",
    "pred_classe = le_classe.inverse_transform(pred_classe_encoded)\n",
    "proba_classe = model_classe.predict_proba(X_classe)\n",
    "\n",
    "print(f\"\\nTop 3 CLASSE predictions:\")\n",
    "top3_classe_indices = np.argsort(proba_classe[0])[-3:][::-1]\n",
    "for i, idx in enumerate(top3_classe_indices, 1):\n",
    "    classe_name = le_classe.classes_[idx]\n",
    "    confidence = proba_classe[0][idx]\n",
    "    print(f\"  {i}. {classe_name}: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# FINAL RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nCATEGORIA: {pred_cat[0]} (confidence: {proba_cat[0][pred_cat_encoded[0]]:.4f})\")\n",
    "print(f\"CLASSE: {pred_classe[0]} (confidence: {proba_classe[0][pred_classe_encoded[0]]:.4f})\")\n",
    "print(f\"\\nFinal prediction: {pred_cat[0]}/{pred_classe[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "# Save results\n",
    "risultato = pd.DataFrame({\n",
    "    'final_prediction': [f\"{pred_cat[0]}/{pred_classe[0]}\"],\n",
    "    'CATEGORIA_top1': [le_categoria.classes_[top3_cat_indices[0]]],\n",
    "    'CATEGORIA_top1_conf': [proba_cat[0][top3_cat_indices[0]]],\n",
    "    'CATEGORIA_top2': [le_categoria.classes_[top3_cat_indices[1]]],\n",
    "    'CATEGORIA_top2_conf': [proba_cat[0][top3_cat_indices[1]]],\n",
    "    'CATEGORIA_top3': [le_categoria.classes_[top3_cat_indices[2]]],\n",
    "    'CATEGORIA_top3_conf': [proba_cat[0][top3_cat_indices[2]]],\n",
    "    'CLASSE_top1': [le_classe.classes_[top3_classe_indices[0]]],\n",
    "    'CLASSE_top1_conf': [proba_classe[0][top3_classe_indices[0]]],\n",
    "    'CLASSE_top2': [le_classe.classes_[top3_classe_indices[1]]],\n",
    "    'CLASSE_top2_conf': [proba_classe[0][top3_classe_indices[1]]],\n",
    "    'CLASSE_top3': [le_classe.classes_[top3_classe_indices[2]]],\n",
    "    'CLASSE_top3_conf': [proba_classe[0][top3_classe_indices[2]]]\n",
    "})\n",
    "risultato.to_csv(\"inference_results/predictions_output.csv\", index=False)\n",
    "\n",
    "# Save SHAP analysis to CSV files\n",
    "shap_top30.to_csv(\"inference_results/shap_top30_features.csv\", index=False)\n",
    "shap_positive.to_csv(\"inference_results/shap_top10_positive.csv\", index=False)\n",
    "shap_negative.to_csv(\"inference_results/shap_top10_negative.csv\", index=False)\n",
    "\n",
    "print(\"\\nResults saved:\")\n",
    "print(\"  - predictions_output.csv\")\n",
    "print(\"  - shap_top30_features.csv\")\n",
    "print(\"  - shap_top10_positive.csv (features that increased probability)\")\n",
    "print(\"  - shap_top10_negative.csv (features that decreased probability)\")\n",
    "print(\"  - prediction_report.png (comprehensive visual report)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
