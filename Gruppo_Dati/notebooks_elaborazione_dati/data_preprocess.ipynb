{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "1dd4b424"
   },
   "source": [
    "### Primary Key del file `.FAB`\n",
    "\n",
    "Ogni **record** del file `.FAB` √® identificato in modo univoco dalla combinazione dei seguenti **6 campi**:\n",
    "\n",
    "| Campo | Nome esteso | Descrizione |\n",
    "|:------|:-------------|:------------|\n",
    "| **CODAMM** | Codice Amministrativo | Identifica il Comune catastale di riferimento. |\n",
    "| **SEZ** | Sezione | Campo attualmente non utilizzato (vuoto). |\n",
    "| **IDIMMO** | Identificativo Immobile | Progressivo univoco dell‚Äôimmobile (Unit√† Immobiliare Urbana) nella banca dati. |\n",
    "| **TIPOIMMO** | Tipo Immobile | Assume valore fisso **F**, che indica *fabbricato* (Catasto Fabbricati). |\n",
    "| **PROGRES** | Progressivo della Situazione | Numero progressivo che individua lo *stato oggettivo* dell‚Äôimmobile nel tempo (versione o mutazione). |\n",
    "| **TIPOREC** | Tipo di Record | Identifica la natura dei dati contenuti nella riga (1‚Äì6). |\n",
    "\n",
    "In sintesi: la combinazione **(CODAMM, SEZ, IDIMMO, TIPOIMMO, PROGRES, TIPOREC)** consente di distinguere in modo univoco ogni record all‚Äôinterno del file `.FAB`.\n",
    "\n",
    "---\n",
    "\n",
    "### Tipologie di record (`TIPOREC`)\n",
    "\n",
    "Ogni **Unit√† Immobiliare Urbana (UIU)** √® descritta da uno o pi√π record, con **TIPOREC** variabile da 1 a 6.  \n",
    "Ogni tipo di record contiene informazioni diverse, ma tutti condividono la stessa PK.\n",
    "\n",
    "| `TIPOREC` | Descrizione | Contenuto principale |\n",
    "|:-----------:|:-------------|:----------------------|\n",
    "| **1** | Dati oggettivi dell‚Äôunit√† immobiliare | Categoria catastale, classe, consistenza, superficie, rendita, dati di atto, piani, partita catastale. |\n",
    "| **2** | Identificativi catastali | Comune catastale (CC), foglio, particella, subalterno, porzioni materiali. |\n",
    "| **3** | Indirizzo e ubicazione | Toponimo/localit√†, indirizzo in italiano e tedesco, numeri civici. |\n",
    "| **4** | Utilit√† comuni | Elenco dei beni comuni non censibili (es. scale, cortili, aree condominiali). |\n",
    "| **5** | Riserve catastali | Segnalazioni tecniche e codici di riserva relativi all‚Äôimmobile. |\n",
    "| **6** | Annotazioni | Note testuali, motivazioni o respingimenti legati alle operazioni catastali. |\n",
    "\n",
    "---\n",
    "\n",
    "### Note\n",
    "\n",
    "- I record con stesso **CODAMM + IDIMMO + PROGRES** appartengono **alla stessa UIU** (stesso immobile e stato).  \n",
    "- I record di tipo 2‚Äì6 sono **record aggiuntivi** legati al record principale di tipo 1.  \n",
    "- Per costruire un dataset ‚Äúflat‚Äù (una riga per immobile), √® necessario **aggregare** o **collegare** i record con la stessa chiave `(CODAMM, IDIMMO, PROGRES)`.\n",
    "\n",
    "*Ancora una volta: la combinazione dei 6 campi che abbiamo detto all'inizio identifica univocamente un record del file FAB. la combinazione dei 3 campi di cui abbiamo parlato alla fine invece ci permette di identificare univocamente un immobile in un certo stato.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "ddddf2f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "ccd3e23a",
    "outputId": "8403b2fb-451e-4b30-f990-ec9f9f20cfc5"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Il percorso √® relativo alla posizione del notebook\n",
    "fab_file = \"../../../dati_AI_per_Challenge/catasto_fabbricati/IDR0000192470_TIPOFACSN_CAMML378.FAB\"\n",
    "\"\"\"\n",
    "Handle the IndexError and the empty strings.\n",
    "Note that not all of the rows in the FAB file have the same length (some records are shorter than others)\n",
    "\"\"\"\n",
    "def safe(parts, i):\n",
    "    return parts[i].strip() if i < len(parts) and parts[i].strip() != \"\" else None\n",
    "\n",
    "\"\"\"\n",
    "Dict that contains all the different types we can find in this file.\n",
    "ex. fab_records['1'] will contain all type 1 records.\n",
    "\"\"\"\n",
    "fab_records = {str(i): [] for i in range(1, 7)}  # types 1‚Äì6\n",
    "\n",
    "with open(fab_file, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"|\")\n",
    "        if len(parts) < 6:\n",
    "            #print(f'we have an invalid row: {parts}') # -> perfect: no invalid rows\n",
    "            continue\n",
    "        CODAMM = safe(parts, 0)\n",
    "        SEZ = safe(parts, 1)\n",
    "        IDIMMO = safe(parts, 2)\n",
    "        TIPOIMMO = safe(parts, 3)\n",
    "        PROGRES = safe(parts, 4)\n",
    "        TIPOREC = safe(parts, 5)\n",
    "\n",
    "        key = (CODAMM, IDIMMO, PROGRES) # this is unique for a property in a certain condition.\n",
    "        base = {\n",
    "            \"CODAMM\": CODAMM,\n",
    "            \"SEZ\": SEZ,\n",
    "            \"IDIMMO\": IDIMMO,\n",
    "            \"TIPOIMMO\": TIPOIMMO,\n",
    "            \"PROGRES\": PROGRES,\n",
    "            \"TIPOREC\": TIPOREC,\n",
    "        }\n",
    "        \"\"\"\n",
    "        As we previously stressed: we have 6 different record types.\n",
    "        \"\"\"\n",
    "        # Record type 1\n",
    "        if TIPOREC == \"1\":\n",
    "            fab_records[\"1\"].append({\n",
    "                **base,\n",
    "                \"ZONA\": safe(parts, 6),\n",
    "                \"CATEGORIA\": safe(parts, 7),\n",
    "                \"CLASSE\": safe(parts, 8),\n",
    "                \"CONSISTENZA\": safe(parts, 9),\n",
    "                \"SUPERFICIE\": safe(parts, 10),\n",
    "                \"RENDITA_EURO\": safe(parts, 13),\n",
    "                \"VALIMIS\": safe(parts, 14),\n",
    "                \"PIANI\": \"|\".join([p for p in parts[18:22] if p]),\n",
    "                \"DATAEFFINI\": safe(parts, 29),\n",
    "                \"DATAEFFFIN\": safe(parts, 30),\n",
    "                \"TIPONOTAINI\": safe(parts, 31),\n",
    "                \"NUMNOTAINI\": safe(parts, 32),\n",
    "                \"ANNO_NOTA\": safe(parts, 34),\n",
    "                \"PARTITAIMM\": safe(parts, 42),\n",
    "                \"IDMUTFIN\": safe(parts, 44),\n",
    "            })\n",
    "\n",
    "        # Record type 2 (identificativi)\n",
    "        elif TIPOREC == \"2\":\n",
    "            fab_records[\"2\"].append({\n",
    "                **base,\n",
    "                \"COMUNE_CATASTALE\": safe(parts, 6),\n",
    "                \"FOGLIO\": safe(parts, 7),\n",
    "                \"PARTICELLA\": safe(parts, 8),\n",
    "                \"SUBALTERNO\": safe(parts, 9),\n",
    "            })\n",
    "\n",
    "        # Record type 3 (indirizzi)\n",
    "        elif TIPOREC == \"3\":\n",
    "            fab_records[\"3\"].append({\n",
    "                **base,\n",
    "                \"TOPONIMO\": safe(parts, 6),\n",
    "                \"INDIRIZZO_ITA\": safe(parts, 7),\n",
    "                \"CIVICO\": safe(parts, 9),\n",
    "            })\n",
    "\n",
    "        # Record type 4 (utilit√† comuni)\n",
    "        elif TIPOREC == \"4\":\n",
    "            fab_records[\"4\"].append({\n",
    "                **base,\n",
    "                \"UCOM_CCPART\": safe(parts, 6),\n",
    "                \"UCOM_FOGLIO\": safe(parts, 7),\n",
    "                \"UCOM_NUMPART\": safe(parts, 8),\n",
    "                \"UCOM_SUB\": safe(parts, 9),\n",
    "            })\n",
    "\n",
    "        # Record type 5 (riserve)\n",
    "        elif TIPOREC == \"5\":\n",
    "            fab_records[\"5\"].append({\n",
    "                **base,\n",
    "                \"RISERVA_COD\": safe(parts, 6),\n",
    "                \"RISERVA_DESCR\": safe(parts, 7),\n",
    "            })\n",
    "\n",
    "        # Record type 6 (annotazioni)\n",
    "        elif TIPOREC == \"6\":\n",
    "            fab_records[\"6\"].append({\n",
    "                **base,\n",
    "                \"COD_ANN\": safe(parts, 6),\n",
    "                \"TESTOANN\": safe(parts, 7),\n",
    "            })\n",
    "\n",
    "# convert to dataframe each fab_records[x] list.\n",
    "dfs = {k: pd.DataFrame(v) for k, v in fab_records.items() if len(v) > 0}\n",
    "for k, df in dfs.items():\n",
    "    print(f\"Type {k}: {len(df)} record\")\n",
    "\n",
    "# create the flat table\n",
    "fab1 = dfs.get(\"1\", pd.DataFrame())\n",
    "fab2 = dfs.get(\"2\", pd.DataFrame())\n",
    "fab3 = dfs.get(\"3\", pd.DataFrame())\n",
    "\n",
    "# aggregate the dataframes\n",
    "def agg_text(df, col, keycols=[\"CODAMM\", \"IDIMMO\", \"PROGRES\"]):\n",
    "    return (\n",
    "        df.groupby(keycols)[col]\n",
    "        .apply(lambda x: \"; \".join([str(i) for i in x if i]))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "fab2agg = agg_text(fab2, \"PARTICELLA\")\n",
    "fab3agg = agg_text(fab3, \"INDIRIZZO_ITA\")\n",
    "fab4agg = agg_text(fab2, \"COMUNE_CATASTALE\")\n",
    "\n",
    "flat = fab1.merge(fab2agg, on=[\"CODAMM\", \"IDIMMO\", \"PROGRES\"], how=\"left\") \\\n",
    "           .merge(fab3agg, on=[\"CODAMM\", \"IDIMMO\", \"PROGRES\"], how=\"left\") \\\n",
    "           .merge(fab4agg, on=[\"CODAMM\", \"IDIMMO\", \"PROGRES\"], how=\"left\")\n",
    "\n",
    "# clean the dataframe\n",
    "flat[\"RENDITA_EURO\"] = (\n",
    "    flat[\"RENDITA_EURO\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .str.extract(r\"([\\d.]+)\", expand=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "flat = flat.sort_values([\"CODAMM\", \"IDIMMO\", \"PROGRES\"])\n",
    "print(\"Total UIU:\", len(flat))\n",
    "\n",
    "\n",
    "null_cols = flat.columns[flat.isna().all()].tolist()\n",
    "print(\"completely empty column:\", null_cols)\n",
    "flat = flat.drop(columns=null_cols)\n",
    "\n",
    "flat.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "Pe7oPhBzxjyh"
   },
   "source": [
    "#Docfa XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "dWxjrUwFdfIq"
   },
   "source": [
    "# Procedura DOCFA ‚Äî Struttura e Significato\n",
    "\n",
    "## Cos‚Äô√® DOCFA\n",
    "\n",
    "**DOCFa** serve per comunicare al **Catasto**:\n",
    "\n",
    "- la **creazione di nuovi immobili** (nuove costruzioni)  \n",
    "- le **modifiche a immobili esistenti** (frazionamenti, fusioni, ampliamenti, cambi d‚Äôuso, ecc.)  \n",
    "- oppure **situazioni particolari** (immobile distrutto, in costruzione, ecc.)\n",
    "\n",
    "---\n",
    "\n",
    "## Struttura di un file Docfa\n",
    "\n",
    "Un **singolo file Docfa** pu√≤ contenere **pi√π immobili o pi√π particelle**.\n",
    "\n",
    "### Intestazioni possibili\n",
    "\n",
    "- **Diverse** ‚Üí se si tratta di **nuove costruzioni**  \n",
    "  **Identificato dal tag `<Accatastamento>`**\n",
    "\n",
    "- **Uniche** ‚Üí se si tratta di **variazioni** (es. fusione di unit√† di uno stesso proprietario)  \n",
    "  **Identificato dal tag `<Variazione>`**\n",
    "\n",
    "**In sintesi:**\n",
    "\n",
    "| Tipo di file | Proprietari | Tag XML |\n",
    "|---------------|--------------|----------|\n",
    "| Nuova costruzione | Possono essere diversi | `<Accatastamento>` |\n",
    "| Variazione | Devono essere gli stessi | `<Variazione>` |\n",
    "\n",
    "Quindi, pi√π immobili nello stesso file:  \n",
    "se √® **una variazione**, stesso proprietario;  \n",
    "se √® **una nuova costruzione**, proprietari diversi.\n",
    "\n",
    "---\n",
    "\n",
    "## Componenti di un documento Docfa\n",
    "\n",
    "Ogni Docfa √® composto da **modelli standard**:\n",
    "\n",
    "- **Modello D1** ‚Üí dati generali della dichiarazione (chi presenta, perch√©, dove, ecc.)  \n",
    "- **Modello 1N ‚Äì Parte I e II** ‚Üí per unit√† delle categorie **A, B, C**  \n",
    "- **Modello 2N ‚Äì Parte I e II** ‚Üí per unit√† delle categorie **D, E**  \n",
    "- **Planimetrie catastali** ‚Üí disegni delle singole unit√† immobiliari  \n",
    "- **Elaborato planimetrico** ‚Üí schema generale del fabbricato  \n",
    "  (necessario se ci sono almeno due unit√†)\n",
    "\n",
    "---\n",
    "\n",
    "## Dettaglio: Modello 1N\n",
    "\n",
    "### Ambito di utilizzo\n",
    "\n",
    "Il **modello 1N parte I** √® usato **solo per le categorie catastali ordinarie**:  \n",
    "A, B, C\n",
    "\n",
    "Viene utilizzato:\n",
    "- sia per **nuove dichiarazioni (Accatastamenti)**  \n",
    "- sia per **variazioni**  \n",
    "ma **non** per le categorie D ed E (che usano il modello 2N)\n",
    "\n",
    "---\n",
    "\n",
    "### Relazione tra Parte I e Parte II\n",
    "\n",
    "Anche se nel Docfa ci sono pi√π unit√† immobiliari:\n",
    "\n",
    "- Il **modello 1N parte I √® uno solo** per tutto il **fabbricato**  \n",
    "- Il **modello 1N parte II √® uno per ciascuna unit√†** (appartamento, negozio, box, ecc.)\n",
    "\n",
    "**In pratica:**\n",
    "\n",
    "| Modello | Riferimento | Contenuto |\n",
    "|----------|--------------|-----------|\n",
    "| 1N Parte I | Fabbricato | Dati generali: indirizzo, strutture, impianti, ecc. |\n",
    "| 1N Parte II | Unit√† immobiliare | Dati specifici: superficie, vani, pertinenze, ecc. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "TpnzZX8FxqoM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_folder = \"../../../dati_AI_per_Challenge/Docfa/Docfa_anonimizzati_2013_2024-12-31\"\n",
    "\n",
    "tags_per_file = {}\n",
    "\n",
    "# Due set distinti per i tipi di documenti\n",
    "accatastamenti = set()\n",
    "variazioni = set()\n",
    "non_classificati = set()\n",
    "\n",
    "for filename in os.listdir(xml_folder):\n",
    "    if filename.lower().endswith(\".xml\"):\n",
    "        path = os.path.join(xml_folder, filename)\n",
    "        try:\n",
    "            tree = ET.parse(path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            tags_and_attrs = set()\n",
    "            for elem in root.iter():\n",
    "                tags_and_attrs.add(elem.tag)\n",
    "                for attr in elem.attrib.keys():\n",
    "                    tags_and_attrs.add(f\"{elem.tag}:{attr}\")\n",
    "\n",
    "            tags_per_file[filename] = tags_and_attrs\n",
    "\n",
    "            # Identifica il tipo di documento\n",
    "            tags_lower = {t.lower() for t in tags_and_attrs}\n",
    "            if \"accatastamento\" in tags_lower:\n",
    "                accatastamenti.add(filename)\n",
    "            elif \"variazione\" in tags_lower:\n",
    "                variazioni.add(filename)\n",
    "            else:\n",
    "                non_classificati.add(filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error while reading {filename}: {e}\")\n",
    "\n",
    "# --- Calcolo tag comuni per accatastamenti e variazioni ---\n",
    "\n",
    "def common_tags_for(files_subset):\n",
    "    \"\"\"Restituisce l'intersezione dei tag per un sottoinsieme di file.\"\"\"\n",
    "    if not files_subset:\n",
    "        return set()\n",
    "    sets = [tags_per_file[f] for f in files_subset if f in tags_per_file]\n",
    "    return set.intersection(*sets) if sets else set()\n",
    "\n",
    "# Tag comuni specifici per tipo documento\n",
    "common_accatastamento = common_tags_for(accatastamenti)\n",
    "common_variazione = common_tags_for(variazioni)\n",
    "\n",
    "# --- Analisi complessiva ---\n",
    "all_fields = set().union(*tags_per_file.values())\n",
    "common_fields_all = set.intersection(*tags_per_file.values()) if tags_per_file else set()\n",
    "\n",
    "print(f\"Total files: {len(tags_per_file)}\")\n",
    "print(f\"Accatastamenti: {len(accatastamenti)} file\")\n",
    "print(f\"Variazioni: {len(variazioni)} file\")\n",
    "print(f\"Non classificati: {len(non_classificati)} file\")\n",
    "\n",
    "print(\"\\n--- TAG COMUNI PER TIPO DI DOCUMENTO ---\")\n",
    "print(f\"Tag comuni negli ACCATASTAMENTI ({len(common_accatastamento)}):\")\n",
    "print(sorted(common_accatastamento))\n",
    "\n",
    "print(f\"\\nTag comuni nelle VARIAZIONI ({len(common_variazione)}):\")\n",
    "print(sorted(common_variazione))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "dIDeWevbdafx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "xml_folder = \"../../../dati_AI_per_Challenge/Docfa/Docfa_anonimizzati_2013_2024-12-31\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for filename in os.listdir(xml_folder):\n",
    "    if not filename.lower().endswith(\".xml\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(xml_folder, filename)\n",
    "    try:\n",
    "        tree = ET.parse(path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # raccoglie tutti i tag (e i nomi degli attributi) in minuscolo\n",
    "        tags_and_attrs = set()\n",
    "        for elem in root.iter():\n",
    "            tags_and_attrs.add(elem.tag.lower())\n",
    "            for attr in elem.attrib.keys():\n",
    "                tags_and_attrs.add(f\"{elem.tag.lower()}:{attr.lower()}\")\n",
    "\n",
    "        # determina il tipo di documento\n",
    "        if \"accatastamento\" in tags_and_attrs:\n",
    "            tipo_docfa = \"Accatastamento\"\n",
    "        elif \"variazione\" in tags_and_attrs:\n",
    "            tipo_docfa = \"Variazione\"\n",
    "        else:\n",
    "            tipo_docfa = \"Sconosciuto\"\n",
    "\n",
    "        records.append({\"file\": filename, \"tipo_docfa\": tipo_docfa})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore in {filename}: {e}\")\n",
    "\n",
    "# crea il dataframe finale\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"tipo_docfa\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "error",
     "timestamp": 1760523348028,
     "user": {
      "displayName": "Guillermo Alejandro Torrealba Espinola",
      "userId": "03687222095085782875"
     },
     "user_tz": -120
    },
    "id": "946N0hXwxthv",
    "outputId": "874dc0e8-6722-4b89-c4de-c30c971a4ec6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organize all the fields of a specific xml file into a python dict.\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_file = \"../../../dati_AI_per_Challenge/Docfa/Docfa_anonimizzati_2013_2024-12-31/0_MUT_1489992_1173741_NCV_41_17_144_0_5_xml_anonymus.xml\"\n",
    "\n",
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "xml_dict = {}\n",
    "\n",
    "for elem in root.iter():\n",
    "    if elem.attrib:\n",
    "        xml_dict[elem.tag] = elem.attrib\n",
    "\n",
    "for k, v in xml_dict.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "PqLIVe1i66Fq"
   },
   "source": [
    "## Leggere Catasto_geometrico\n",
    "\n",
    "Funzione per leggere i file dentro `.shp` dentro la cartella selezionata.\n",
    "L'idea dietro questo √® che i punti trovati dentro i `.shp` file hanno le cordinate geografiche, quindi si potrebbe cercare un modo per collegarli con le unita immobiliare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "HNliOaJt63qJ"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def process_shapefiles_in_directory(folder_path, save_csv=False):\n",
    "    \"\"\"\n",
    "    Reads all .shp files in the given folder and creates 4 DataFrames for each:\n",
    "     - df_attributes\n",
    "     - df_geometry\n",
    "     - df_projection\n",
    "     - df_metadata\n",
    "    Optionally saves them to CSV.\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    shp_files = list(folder.glob(\"*.shp\"))\n",
    "\n",
    "    if not shp_files:\n",
    "        print(f\"No .shp files found in {folder}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(shp_files)} shapefiles in {folder}\\n\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for shp_path in shp_files:\n",
    "        print(f\"üîπ Processing: {shp_path.name}\")\n",
    "        try:\n",
    "            gdf = gpd.read_file(shp_path)\n",
    "\n",
    "            # === 1. Attribute table ===\n",
    "            df_attributes = pd.DataFrame(gdf.drop(columns=\"geometry\"))\n",
    "\n",
    "            # === 2. Geometry ===\n",
    "            df_geometry = gdf[[\"geometry\"]].copy()\n",
    "\n",
    "            # === 3. Projection info ===\n",
    "            crs = gdf.crs.to_string() if gdf.crs else None\n",
    "            df_projection = pd.DataFrame([{\"CRS\": crs}])\n",
    "\n",
    "            # === 4. Metadata ===\n",
    "            df_metadata = pd.DataFrame({\n",
    "                \"Column\": gdf.columns,\n",
    "                \"Type\": [str(gdf[col].dtype) for col in gdf.columns],\n",
    "                \"Has Nulls\": [gdf[col].isnull().any() for col in gdf.columns]\n",
    "            })\n",
    "\n",
    "            # Store results in dict\n",
    "            results[shp_path.stem] = {\n",
    "                \"attributes\": df_attributes,\n",
    "                \"geometry\": df_geometry,\n",
    "                \"projection\": df_projection,\n",
    "                \"metadata\": df_metadata\n",
    "            }\n",
    "\n",
    "            # === Optional: save CSV files ===\n",
    "            if save_csv:\n",
    "                prefix = folder / shp_path.stem\n",
    "                df_attributes.to_csv(f\"{prefix}_attributes.csv\", index=False)\n",
    "                df_geometry.to_csv(f\"{prefix}_geometry.csv\", index=False)\n",
    "                df_projection.to_csv(f\"{prefix}_projection.csv\", index=False)\n",
    "                df_metadata.to_csv(f\"{prefix}_metadata.csv\", index=False)\n",
    "                print(f\"‚úÖ Saved CSVs for {shp_path.name}\")\n",
    "\n",
    "            print(f\"   CRS: {crs}\")\n",
    "            print(f\"   Columns: {list(gdf.columns)}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {shp_path.name}: {e}\\n\")\n",
    "\n",
    "    print(\"All shapefiles processed successfully ‚úÖ\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# === Example usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"../../../dati_AI_per_Challenge/catasto_geometrico/406_shp\"  # replace with your folder path\n",
    "    all_results = process_shapefiles_in_directory(folder_path, save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "nqtJ0EvX8YIL"
   },
   "outputs": [],
   "source": [
    "## ESEMPIO\n",
    "directory=\"../../../dati_AI_per_Challenge/catasto_geometrico/406_shp\" \n",
    "r=process_shapefiles_in_directory(directory)\n",
    "for k,v in r.items():\n",
    "  print(k)\n",
    "  display(v[\"attributes\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "25jH1rY78k59"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virt_env_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
